{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5eced2",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network with Back Propagation\n",
    "\n",
    "The objective of this notebook is to implement smartly and scalably a fully connected neural network that will be trained by means of a gradient descent back propagation algorithm. Afterwards I will build a neural net with a few layers to classify gas gazzlers from the mtcars data set and another network to predict mpg.\n",
    "\n",
    "* Get the mtcars data, bulid features and also divide into train and test\n",
    "* Create classes and methods for marticular modules - linear and activation of the neural network\n",
    "* Create a neural network class which is build out of modules and can be trained. \n",
    "* Train the network on mtcars and see if we are getting any reasonable results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a53c1d8",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "976a25d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def load_data(path):\n",
    "    '''\n",
    "    takes path and returns a pnadas data frame object with the data from file under path\n",
    "    '''\n",
    "    data = []\n",
    "    with open(path) as f:\n",
    "        for row in csv.DictReader(f, delimiter='\\t'):\n",
    "            data.append(row)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def one_hot(x):\n",
    "    '''\n",
    "    @param x : pandas series object\n",
    "    returns a data frame with the original series and the one hot encoded fields\n",
    "    '''\n",
    "    \n",
    "    new_frame = pd.DataFrame(x)\n",
    "    for val in x.unique():\n",
    "        _name = str(int(val))\n",
    "        new_frame[x.name + _name] = new_frame.apply(lambda col: 1 if col[x.name] == val else 0, axis=1)\n",
    "    return new_frame.iloc[:,1:]\n",
    "        \n",
    "    \n",
    "def standardize(x):\n",
    "    '''\n",
    "    @param x : string holding the name of the field to be standarized\n",
    "    '''\n",
    "    z = x.astype('float')\n",
    "    result = np.array((z - np.mean(z))/np.std(z))\n",
    "\n",
    "    return pd.DataFrame(result, columns=[x.name])\n",
    "\n",
    "\n",
    "def make_features(feature_list):\n",
    "    '''\n",
    "    @param feature_list: a list of tuples, first entry is a pandas series and the next one is a string with \n",
    "    onehot or standardize. \n",
    "    '''\n",
    "    new_features = []\n",
    "    for f,ftype in feature_list:\n",
    "        if ftype == 'onehot':\n",
    "            new_features.append(one_hot(f))\n",
    "        elif ftype == 'standardize':\n",
    "            new_features.append(standardize(f))\n",
    "        else:\n",
    "            new_features.append(f)\n",
    "        \n",
    "    return pd.concat(new_features, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "auto_data = load_data('../code_and_data_for_hw05/auto-mpg-regression.tsv')\n",
    "\n",
    "\n",
    "features = [\n",
    "            (auto_data.cylinders, 'onehot'),\n",
    "            (auto_data.displacement, 'standardize'),\n",
    "            (auto_data.horsepower, 'standardize'),\n",
    "            (auto_data.weight, 'standardize'),\n",
    "            (auto_data.acceleration, 'standardize'),\n",
    "            (auto_data.origin, 'onehot'),\n",
    "            (auto_data.mpg, 'standardize')\n",
    "            ]\n",
    "\n",
    "\n",
    "auto_data = make_features(features)\n",
    "\n",
    "\n",
    "# Keep this for future reference:\n",
    "mean_mpg, sigma_mpg = auto_data['mpg'].astype('float').mean(), auto_data['mpg'].astype('float').std() \n",
    "\n",
    "\n",
    "# Transpose  data and divide into training and testing sets:\n",
    "X = (auto_data.T).iloc[:-1, :]\n",
    "Y = (auto_data.T).iloc[[-1], :]\n",
    "\n",
    "# Divide at random into test and train. The test data set will be approzimately 20% of the entire data set\n",
    "test_ind = np.random.choice(range(X.shape[1]), int(0.2 * X.shape[1]), replace = False)\n",
    "train_ind = np.array(list(set(range(X.shape[1]))- set(test_ind)))\n",
    "\n",
    "X_test, Y_test = np.array(X.iloc[:, test_ind]), np.array(Y.iloc[:, test_ind])\n",
    "X_train, Y_train = np.array(X.iloc[:, train_ind]), np.array(Y.iloc[:, train_ind])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c7aa7",
   "metadata": {},
   "source": [
    "### Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc5a3928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W  (4, 3)\n",
      "input  (3, 2)\n",
      "input A  (3, 2)\n",
      "output Z  (4, 2)\n",
      "dLdZ  (4, 2)\n",
      "dLdA  (3, 2)\n",
      "dLdW  (4, 3)\n"
     ]
    }
   ],
   "source": [
    "class Linear(object):\n",
    "    def __init__(self, m,n):\n",
    "        '''\n",
    "            This is the linear part that takes in m inputs, multiplies by weights and produces n outputs\n",
    "            m - number of imputs\n",
    "            n - number of outputs\n",
    "        '''\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.W = np.random.normal(loc=0.0, scale=1.0, size=self.m * self.n).reshape((self.n, self.m))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        '''\n",
    "            X are the inputs. The forward method will produce and save activations and also return them\n",
    "        '''\n",
    "        assert X.shape[0] == self.m\n",
    "        self.A = X  # if self is layer l, then self.A is l-1 layer, the inputs to this module\n",
    "        self.Z  = np.matmul(self.W, X)\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, dLdZ):\n",
    "        '''\n",
    "            dLdZ is passed from the activation layer. We can compyte dLdA = dLdZ * dZdA, but dZdA = W\n",
    "            and pass it to the previous activation layer. \n",
    "            knowing dLdZ, we compute dLdW = dLdZ * dZdW = dLdZ * A(l-1)  and store it\n",
    "        '''\n",
    "        self.dLdA = np.matmul((self.W).T, dLdZ)\n",
    "        self.dLdW = np.matmul(self.A, dLdZ.T).T\n",
    "        return self.dLdA\n",
    "    \n",
    "    def udpdate(self, lrate):\n",
    "        '''\n",
    "            just update weights \n",
    "        '''\n",
    "        self.W = self.W - lrate * self.dLdW\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "X = np.array([[2,3],[2,3],[1,1]])    \n",
    "L1 = Linear(3,4)\n",
    "print('W ', L1.W.shape)\n",
    "print('input ', X.shape)\n",
    "L1.forward(X)\n",
    "\n",
    "print('input A ',L1.A.shape)\n",
    "\n",
    "print('output Z ', L1.Z.shape)\n",
    "dLdZ = np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "\n",
    "print('dLdZ ', dLdZ.shape)\n",
    "L1.backward(dLdZ)\n",
    "\n",
    "print('dLdA ', L1.dLdA.shape)\n",
    "print('dLdW ', L1.dLdW.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6922aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(object):\n",
    "    def __init__(self, m):\n",
    "        '''\n",
    "            the activation module will take an input of m from the previous linear module and also return m \n",
    "            elements being the images of ReLU function applied on those elements\n",
    "        '''\n",
    "        self.m = m\n",
    "    \n",
    "    def forward(self, X):\n",
    "        '''\n",
    "            Take an X as input and apply ReLU elementwise\n",
    "        '''\n",
    "        def ReLU(x):\n",
    "            return x if x>=0 else 0\n",
    "        self.A = X\n",
    "        self.Z = np.vectorize(lambda x: ReLU(x))(self.A)\n",
    "        return self.Z\n",
    "\n",
    "    def backward(self, dLdA):\n",
    "        '''\n",
    "            Takes dLdA, where dA means with respect to the output of the module.  \n",
    "            Returns dLdZ (Z is the input to the module). dLdZ = dLdA * dAdZ , but dAdZ is ReLU_grad\n",
    "        '''\n",
    "        def ReLU_grad(x):\n",
    "            return 1 if x>=0 else 0\n",
    "        return dLdA * np.vectorize(lambda x: ReLU_grad(x))(self.A) \n",
    "    \n",
    "    \n",
    "R = ReLU(4)  \n",
    "a = L1.forward(np.array([[2,3],[2,3],[1,1]]))\n",
    "print(a)\n",
    "R.forward(a)\n",
    "dLdA = np.array([[0.6, 0.3], [0.9,1],[3,3],[1.2, 3.4]])\n",
    "R.backward(dLdA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class quadratic_loss():\n",
    "    def __init__(self, m):\n",
    "        '''\n",
    "            m is the number of inputs which is the number of outputs of the last module\n",
    "        '''\n",
    "        self.m = m\n",
    "    \n",
    "    def q_loss(self, Ypred, Y):\n",
    "        '''\n",
    "            simple quadratic loss\n",
    "        '''\n",
    "        return ((Y - Ypred)**2).sum()/(Ypred.shape[0])\n",
    "    \n",
    "    def q_loss_grad(self, Ypred, Y):\n",
    "        '''\n",
    "            quadratic loss gradient\n",
    "        '''\n",
    "        self.A = Ypred\n",
    "        self.dLdA = 2*(Y - Ypred).sum()/(Ypred.shape[0])\n",
    "        return self.dLdA\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552cd245",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn():\n",
    "    def __init__(self, modules, loss_module):\n",
    "        self.modules = modules\n",
    "        self.loss_module = loss_module\n",
    "        \n",
    "    def forward(X):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
