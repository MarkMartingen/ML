{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb8d3dc",
   "metadata": {},
   "source": [
    "# MNIST digit recognition\n",
    "\n",
    "In this notebook I am going to use Keras to make two networks for digit recognition. The first network will be a a simple feed forward network. The second one will include convolutions (filters and max pooling layers) and it will also contain some regularization. The idea is to play around with Keras and see ho much better can we get using CNN networks.\n",
    "\n",
    "* Downlaod and flatten the MNIST data set and prepare training and test subsets\n",
    "* Creagte a simple two feed forward network with one hidden layer\n",
    "* Create a CNN network according to the following architecture:\n",
    "    * A convolutional layer with 32 filters of size 3 × 3, with a ReLU activation\n",
    "    * A max pooling layer with size 2 × 2\n",
    "    * A convolutional layer with 64 filters of size 3 × 3, with ReLU activation\n",
    "    * A max pooling layer with size 2 × 2\n",
    "    * A flatten layer\n",
    "    * A fully connected layer with 128 neurons, with ReLU activation\n",
    "    * A dropout layer with drop probability 0.5\n",
    "    * A fully-connected layer with 10 neurons with softmax\n",
    "* Compare accuracies on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17898b3e",
   "metadata": {},
   "source": [
    "## Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2eb43a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Input\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import Callback\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "tf.config.run_functions_eagerly(True) # needed for cnn network. Found on stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "31e35d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the MNIST data set:\n",
    "def get_mnist(flatten=True):\n",
    "    '''\n",
    "        load MIST data using keras datasets\n",
    "    '''\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    #standarize:\n",
    "    X_train = X_train/255\n",
    "    X_test = X_test/255\n",
    "    \n",
    "    if flatten:\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]*X_test.shape[2]))\n",
    "    \n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test  = to_categorical(y_test, 10)\n",
    "    return X_train, y_train, X_test, y_test \n",
    "\n",
    "\n",
    "def shifted(X, shift):\n",
    "    '''\n",
    "        increase the image size to size+shift randomly shifting \n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "    size = m + shift\n",
    "    X_sh = np.zeros((n, size, size))\n",
    "    for i in range(n):\n",
    "        sh1 = np.random.randint(shift)\n",
    "        sh2 = np.random.randint(shift)\n",
    "        X_sh[i, sh1:sh1+m, sh2:sh2+m] = X[i, :, :]\n",
    "    return X_sh\n",
    "\n",
    "data = get_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dd1a42",
   "metadata": {},
   "source": [
    "## Make a two layer fully connectged feed forwards network\n",
    "The network architecture will be as follows:\n",
    "\n",
    "[flat input]--->[512 units with ReLU activation]--->[256 unites with ReLU activation]---->[10 units with softmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3e7193e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "layers = [\n",
    "    Dense(input_dim=28**2, units=512, activation=\"relu\"),\n",
    "    Dense(units=256, activation=\"relu\"),\n",
    "    Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = Sequential(layers)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "83459e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will run the model a few times and return the average test accuracy\n",
    "def run_model(model, data, batch_size, epochs, split, verbose, num_trials):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = data\n",
    "\n",
    "    global_test_acc = 0\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        print('trial number: {} --------------------------'.format(i+1))\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=split, verbose=verbose)\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "        \n",
    "        global_test_acc += test_acc\n",
    "        \n",
    "        # reset the weights after each trial but not for the last, as I want to keep a trained model\n",
    "        if i<num_trials-1:\n",
    "            for ix, layer in enumerate(model.layers):\n",
    "                if hasattr(model.layers[ix], 'kernel_initializer') and hasattr(model.layers[ix], 'bias_initializer'):\n",
    "                    weight_initializer = model.layers[ix].kernel_initializer\n",
    "\n",
    "                    bias_initializer = model.layers[ix].bias_initializer\n",
    "\n",
    "                    old_weights, old_biases = model.layers[ix].get_weights()\n",
    "\n",
    "                    model.layers[ix].set_weights([\n",
    "                        weight_initializer(shape=old_weights.shape),\n",
    "                        bias_initializer(shape=old_biases.shape)])\n",
    "    print('\\nThe tes accuracy in {} trials is {:.3f}'.format(num_trials, global_test_acc/num_trials))    \n",
    "    return global_test_acc/num_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4771a",
   "metadata": {},
   "source": [
    "I will now train the network with 3 epochs and a batch size of 32 and see what is its accuracy. I also use a split=0.1, to so that the network, for each epoch, trains on 90% of the data. This is to see if it is not overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d6e0f3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number: 1 --------------------------\n",
      "1688/1688 - 73s - loss: 0.1985 - accuracy: 0.9395 - val_loss: 0.0889 - val_accuracy: 0.9735 - 73s/epoch - 43ms/step\n",
      "trial number: 2 --------------------------\n",
      "1688/1688 - 69s - loss: 0.1901 - accuracy: 0.9412 - val_loss: 0.0949 - val_accuracy: 0.9707 - 69s/epoch - 41ms/step\n",
      "trial number: 3 --------------------------\n",
      "1688/1688 - 54s - loss: 0.1865 - accuracy: 0.9431 - val_loss: 0.0868 - val_accuracy: 0.9733 - 54s/epoch - 32ms/step\n",
      "\n",
      "The tes accuracy in 3 trials is 0.969\n"
     ]
    }
   ],
   "source": [
    "ff_network_acc = run_model(\n",
    "                    model,\n",
    "                    data, \n",
    "                    batch_size=32,\n",
    "                    epochs=1,\n",
    "                    split=0.1,\n",
    "                    verbose=2,\n",
    "                    num_trials=3\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b31577",
   "metadata": {},
   "source": [
    "This network seems to do a pretty good job with an accurac of 97%. Just to convince myself that this is really the case, let me try to select at random 5 digits and see if the network gets them all correctly. It should with the following probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3eda7cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probabilty of making no mistakes in predicting 5 ranodm digits is 0.8560814684790844\n",
      "\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The digit under 9538 is 4\n",
      "The network prediction is  4\n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "The digit under 7963 is 8\n",
      "The network prediction is  8\n",
      "\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "The digit under 1914 is 8\n",
      "The network prediction is  8\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "The digit under 8686 is 5\n",
      "The network prediction is  5\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "The digit under 1428 is 9\n",
      "The network prediction is  9\n",
      "\n",
      "The network mande 0 mistakes in 5 randomly chosen digits\n"
     ]
    }
   ],
   "source": [
    "def sanity_check(model,data, num,ff_network_acc):\n",
    "    prob = ff_network_acc**num\n",
    "    print('The probabilty of making no mistakes in predicting {} ranodm digits is {}'.format(num, prob))\n",
    "    print()\n",
    "\n",
    "    x,y = (data[2], data[3])\n",
    "    ind = np.random.choice(range(x.shape[0]), size=num, replace=False, p=None)\n",
    "    mistakes = 0\n",
    "    for i in ind:\n",
    "        true_val = np.argmax(y[i])\n",
    "        network_pred = np.argmax(model.predict(x[[i],:]))\n",
    "        print('The digit under {} is {}'.format(i, true_val))\n",
    "        print('The network prediction is  {}'.format(network_pred))\n",
    "        print()\n",
    "        if int(true_val) != int(network_pred):\n",
    "            mistakes += 1\n",
    "\n",
    "    print('The network mande {} mistakes in 5 randomly chosen digits'.format(mistakes))\n",
    "    \n",
    "\n",
    "sanity_check(model,data,5 ,ff_network_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7d756d",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "The fully connected feed forward network does a pretty good job, but I want to see if a CNN network can do a little better. I am going to use the following architecture, which is not a result of my trial and error, but it was suggested in a homework assignment (course 6.036 MIT)\n",
    "* A convolutional layer with 32 filters of size 3 × 3, with a ReLU activation\n",
    "* A max pooling layer with size 2 × 2\n",
    "* A convolutional layer with 64 filters of size 3 × 3, with ReLU activation\n",
    "* A max pooling layer with size 2 × 2\n",
    "* A flatten layer\n",
    "* A fully connected layer with 128 neurons, with ReLU activation\n",
    "* A dropout layer with drop probability 0.5\n",
    "* A fully-connected layer with 10 neurons with softmax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b3086612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 25, 25, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 23, 23, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 22, 22, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 30976)             0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 128)               3965056   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,985,162\n",
      "Trainable params: 3,985,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers_cnn = [\n",
    "            Conv2D(input_shape = (28,28,1), filters=32 , kernel_size=(3, 3), activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'),\n",
    "            Conv2D(filters=64 , kernel_size=(3, 3), activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'),\n",
    "            Flatten(),\n",
    "            Dense(units = 128, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model_cnn = Sequential(layers_cnn)\n",
    "model_cnn.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815fbd55",
   "metadata": {},
   "source": [
    "Now I will train the cnn network and see if it does any better. I will use only one trial and one epoch due becuse otherwise the learning takes a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "532726f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number: 1 --------------------------\n",
      "1688/1688 - 222s - loss: 0.1702 - accuracy: 0.9487 - val_loss: 0.0393 - val_accuracy: 0.9897 - 222s/epoch - 132ms/step\n",
      "\n",
      "The tes accuracy in 1 trials is 0.985\n"
     ]
    }
   ],
   "source": [
    "data_cnn = get_mnist(flatten=False)\n",
    "\n",
    "cnn_network_acc = run_model(\n",
    "                    model_cnn,\n",
    "                    data_cnn, \n",
    "                    batch_size=32,\n",
    "                    epochs=1,\n",
    "                    split=0.1,\n",
    "                    verbose=2,\n",
    "                    num_trials=1\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729c11b",
   "metadata": {},
   "source": [
    "## Comparing the networks\n",
    "\n",
    "Looking at sheer accuracy, the CNN networks performs slightly better as expected. I also want to observe if the CNN network is more robust when working with images of digits thare are somewhat uncentered. To do this I wll make another data set that will be randomly shifted and I will compare both the CNNN and the fully connected feed forwards network in this shifted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9024bee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shift the data sets by 10 (randomly)\n",
    "data_sh_cnn = (shifted(data_cnn[0],20), data_cnn[1], shifted(data_cnn[2],20), data_cnn[3])\n",
    "\n",
    "data_sh_fc = ( \n",
    "            data_sh_cnn[0].reshape((data_sh_cnn[0].shape[0], data_sh_cnn[0].shape[1]*data_sh_cnn[0].shape[2])),\n",
    "            data_sh_cnn[1],\n",
    "            data_sh_cnn[2].reshape((data_sh_cnn[2].shape[0], data_sh_cnn[2].shape[1]*data_sh_cnn[2].shape[2])),\n",
    "            data_sh_cnn[3]\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "4a48bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the architecture, as the first input layer now takes in different input size\n",
    "layers_sh = [\n",
    "            Dense(input_dim=48**2, units=512, activation=\"relu\"),\n",
    "            Dense(units=256, activation=\"relu\"),\n",
    "            Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "layers_cnn_sh = [\n",
    "            Conv2D(input_shape = (48,48,1), filters=32 , kernel_size=(3, 3), activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'),\n",
    "            Conv2D(filters=64 , kernel_size=(3, 3), activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'),\n",
    "            Flatten(),\n",
    "            Dense(units = 128, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "model_sh = Sequential(layers_sh)\n",
    "model_cnn_sh = Sequential(layers_cnn_sh)\n",
    "\n",
    "model_sh.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "model_cnn_sh.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "97863909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number: 1 --------------------------\n",
      "1688/1688 - 55s - loss: 0.7869 - accuracy: 0.7385 - val_loss: 0.3701 - val_accuracy: 0.8828 - 55s/epoch - 33ms/step\n",
      "\n",
      "The tes accuracy in 1 trials is 0.875\n"
     ]
    }
   ],
   "source": [
    "ff_network_acc_sh = run_model(\n",
    "                    model_sh,\n",
    "                    data_sh_fc, \n",
    "                    batch_size=32,\n",
    "                    epochs=1,\n",
    "                    split=0.1,\n",
    "                    verbose=2,\n",
    "                    num_trials=1\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b15e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number: 1 --------------------------\n"
     ]
    }
   ],
   "source": [
    "cnn_network_acc_sh = run_model(\n",
    "                    model_cnn_sh,\n",
    "                    data_sh_cnn, \n",
    "                    batch_size=32,\n",
    "                    epochs=1,\n",
    "                    split=0.1,\n",
    "                    verbose=2,\n",
    "                    num_trials=1\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29948aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy of the fully connected feed forward NN dropped from {:.3f} to {:.3f}\\n'\n",
    "      .format(ff_network_acc, ff_network_acc_sh))\n",
    "\n",
    "      \n",
    "print('The accuracy of the CNN network dropped from {:.3f} to {:.3f}'\n",
    "      .format(cnn_network_acc, cnn_network_acc_sh))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
